{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Initial player ratings\n",
    "ratings = {\n",
    "    # ... add all players here\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_processed.csv') as f:\n",
    "    data = pd.read_csv(f)\n",
    "    \n",
    "X = [i for i in zip(data['Players 1'], data['Players 2'])]\n",
    "y = [i for i in zip(data['New Score 1'], data['New Score 2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-0.1*x))\n",
    "\n",
    "def average_team_rating(p1, p2, ratings):\n",
    "    if p1 not in ratings:\n",
    "        ratings[p1] = 100\n",
    "    if p2 not in ratings:\n",
    "        ratings[p2] = 100\n",
    "    return np.mean([ratings[p1], ratings[p2]])\n",
    "\n",
    "def update_ratings(ratings, team1_p1, team1_p2, team2_p1, team2_p2, predicted, actual):\n",
    "    error = actual - predicted\n",
    "    learning_rate = 0.5  # this can be adjusted\n",
    "    ratings[team1_p1] += learning_rate * error\n",
    "    ratings[team1_p2] += learning_rate * error\n",
    "    ratings[team2_p1] -= learning_rate * error\n",
    "    ratings[team2_p1] -= learning_rate * error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n",
      "Train loss: 2794.5\n",
      "Train accuracy: 0.3313651816067275\n",
      "Test loss: 699.0\n",
      "Test accuracy: 0.33261802575107297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dummy training data example:\n",
    "# Each entry is a tuple (team1, team2, outcome)\n",
    "# Outcome is 1 if team1 wins, 0 otherwise.\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for _ in range(100):  # Adjust the number of iterations as needed\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_num = 0\n",
    "    for match, result in zip(X_train, y_train):\n",
    "        team1, team2, outcome = match[0], match[1], result[0]\n",
    "        team1_p1, team1_p2 = team1.split(', ')\n",
    "        team2_p1, team2_p2 = team1.split(', ')\n",
    "        avg_rating_team1 = average_team_rating(team1_p1, team1_p2, ratings)\n",
    "        avg_rating_team2 = average_team_rating(team2_p1, team2_p2, ratings)\n",
    "        diff = avg_rating_team1 - avg_rating_team2\n",
    "        pred = sigmoid(diff)\n",
    "        train_loss += np.abs(update_ratings(ratings, team1_p1, team1_p2, team2_p1, team2_p2, pred, outcome))\n",
    "        rounded_pred = round(pred)\n",
    "        if rounded_pred == outcome:\n",
    "            train_correct += 1\n",
    "        train_num += 1\n",
    "\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f\"Train accuracy: {train_correct/train_num}\")\n",
    "\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_num = 0\n",
    "    for match, result in zip(X_test, y_test):\n",
    "        team1, team2, outcome = match[0], match[1], result[0]\n",
    "        team1_p1, team1_p2 = team1.split(', ')\n",
    "        team2_p1, team2_p2 = team1.split(', ')\n",
    "        avg_rating_team1 = average_team_rating(team1_p1, team1_p2, ratings)\n",
    "        avg_rating_team2 = average_team_rating(team2_p1, team2_p2, ratings)\n",
    "        diff = avg_rating_team1 - avg_rating_team2\n",
    "        pred = sigmoid(diff)\n",
    "        test_loss += np.abs(pred-outcome)\n",
    "        rounded_pred = round(pred)\n",
    "        if rounded_pred == outcome:\n",
    "            test_correct += 1\n",
    "        test_num += 1\n",
    "    \n",
    "    print(f'Test loss: {test_loss}')\n",
    "    print(f\"Test accuracy: {test_correct/test_num}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
